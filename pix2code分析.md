pix2code论文
从原理图上看使用了三个神经网络分别为：视觉模型(用卷积神经网络cnn)、语言模型(长短记忆模型lstm)、复合模型(双层长短记忆模型lstm')

CNN处理输入的视觉稿，输出是一个符号标识、LSTM处理输入代码输出也是一个符号标识、lstm'用来关联匹配最终输出目标代码

虽然论文中有讲到三个神经网络的每个网络层具体如何构建，但是没有明确指出视觉稿的特征提取方法、DSL code如何转化target code，所以github上的pix2codeReimplement(这个重新实现是非官方的人实现的)运行起来并没有最终输出的效果
